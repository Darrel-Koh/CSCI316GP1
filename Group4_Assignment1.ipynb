{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from datetime import datetime\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_predict, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\User\\Documents\\Singapore Institute of Management - Bachelor\\CSCI316 - Big Data Mining Techniques and Implementation\\Group Assignment\\Group Assignment 1/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the null value in each attributes\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rev_hi_lim \n",
    "\n",
    "# Fill missing values in total_rev_hi_lim with Simple Imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "total_rev_hi_lim = df['total_rev_hi_lim'].values.reshape(-1,1)\n",
    "total_rev_hi_lim_imputed = imputer.fit_transform(total_rev_hi_lim)\n",
    "df['total_rev_hi_lim'] = total_rev_hi_lim_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home_ownership \n",
    "\n",
    "# Remove rows with value ANY\n",
    "\n",
    "df = df[df['home_ownership'] != 'ANY']\n",
    "df['home_ownership'].unique()\n",
    "\n",
    "# Level encoding for home ownership \n",
    "\n",
    "home_type = ['RENT', 'OWN', 'MORTGAGE', 'OTHER', 'NONE']  # Unique values for encoding\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(home_type)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['home_ownership'] = encoder.transform(df['home_ownership'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose \n",
    "\n",
    "# Label encoding for purpose\n",
    "\n",
    "df['purpose'].unique()\n",
    "\n",
    "purposes = ['credit_card', 'car', 'small_business', 'other', 'wedding',\n",
    "       'debt_consolidation', 'home_improvement', 'major_purchase',\n",
    "       'medical', 'moving', 'vacation', 'house', 'renewable_energy',\n",
    "       'educational']\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(purposes)\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['purpose'] = encoder.transform(df['purpose'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_grade\n",
    "\n",
    "# Sort the order of subgrades and do label encoding\n",
    "\n",
    "subgrades = ['B2', 'C4', 'C5', 'C1', 'B5', 'A4', 'E1', 'F2', 'C3', 'B1', 'D1',\n",
    "       'A1', 'B3', 'B4', 'C2', 'D2', 'A3', 'A5', 'D5', 'A2', 'E4', 'D3',\n",
    "       'D4', 'F3', 'E3', 'F4', 'F1', 'E5', 'G4', 'E2', 'G3', 'G2', 'G1',\n",
    "       'F5', 'G5']\n",
    "\n",
    "def custom_sort_key(subgrade):\n",
    "    match = re.match(r'([A-Za-z]+)(\\d+)', subgrade)\n",
    "    letter = match.group(1)\n",
    "    number = int(match.group(2))\n",
    "    \n",
    "    return letter, number\n",
    "\n",
    "sorted_subgrades = sorted(subgrades, key=custom_sort_key)\n",
    "\n",
    "# Level encoding for sorted sub-grade \n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(sorted_subgrades)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['sub_grade'] = encoder.transform(df['sub_grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employment_lengths\n",
    "\n",
    "employment_lengths = ['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years', 'nan']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder with unique values\n",
    "label_encoder.fit(employment_lengths)\n",
    "\n",
    "# Encode the attribute values\n",
    "df['emp_length'] = label_encoder.transform(df['emp_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_delinq\n",
    "\n",
    "df['mths_since_last_delinq'] = df['mths_since_last_delinq'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_record\n",
    "\n",
    "df['mths_since_last_record'] = df['mths_since_last_record'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revol_util\n",
    "# Handle missing value with imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "revol_util = df['revol_util'].values.reshape(-1,1)\n",
    "\n",
    "revol_util_imputed = imputer.fit_transform(revol_util)\n",
    "\n",
    "df['revol_util'] = revol_util_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate annual_inc and annual_inc_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'annual_inc'] = df.loc[df['application_type'] == 'JOINT', 'annual_inc_joint']\n",
    "df = df.drop('annual_inc_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dti_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'dti'] = df.loc[df['application_type'] == 'JOINT', 'dti_joint']\n",
    "df = df.drop('dti_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification_status_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'verification_status'] = df.loc[df['application_type'] == 'JOINT', 'verification_status_joint']\n",
    "df = df.drop('verification_status_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term \n",
    "# Label encoding for term\n",
    "\n",
    "term = [' 36 months', ' 60 months']  # Unique values for encoding\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(term)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['term'] = encoder.transform(df['term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification_status\n",
    "\n",
    "veri = ['Not Verified', 'Source Verified', 'Verified']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(veri)\n",
    "\n",
    "\n",
    "df['verification_status'] = encoder.transform(df['verification_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymnt_plan\n",
    "\n",
    "plan = ['n', 'y']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(plan)\n",
    "df['pymnt_plan'] = encoder.transform(df['pymnt_plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application_type\n",
    "\n",
    "type = ['INDIVIDUAL', 'JOINT'] # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(type)\n",
    "\n",
    "df['application_type'] = encoder.transform(df['application_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initial_list_status\n",
    "\n",
    "status = ['f', 'w'] # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(status)\n",
    "\n",
    "df['initial_list_status'] = encoder.transform(df['initial_list_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing last credit pull\n",
    "df['last_credit_pull_d'].fillna(\"01-01-2016\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit History Length:\n",
    "# Calculated as: last_credit_pull - earliest_cr_line\n",
    "def date_difference(date_str1, date_str2):\n",
    "    # Convert date strings to datetime objects\n",
    "    date_format = \"%d-%m-%Y\"\n",
    "    date1 = datetime.strptime(date_str1, date_format)\n",
    "    date2 = datetime.strptime(date_str2, date_format)\n",
    "\n",
    "    # Calculate the difference\n",
    "    difference = date2 - date1\n",
    "\n",
    "    # Return the difference in days\n",
    "    return difference.days\n",
    "\n",
    "df['credit_history_length'] = df.apply(lambda row: date_difference(row['earliest_cr_line'], row['last_credit_pull_d']), axis=1)\n",
    "\n",
    "# Swap the values and column names\n",
    "df['default_ind'], df['credit_history_length'] = df['credit_history_length'], df['default_ind']\n",
    "df.rename(columns={'default_ind': 'credit_history_length', 'credit_history_length': 'default_ind'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop not usable attributes \n",
    "\n",
    "remove_col = [\n",
    "    'id',\n",
    "    'member_id',\n",
    "    'emp_title',\n",
    "    'issue_d',\n",
    "    'desc',\n",
    "    'title',\n",
    "    'zip_code',\n",
    "    'addr_state',\n",
    "    'earliest_cr_line',\n",
    "    'last_pymnt_d',\n",
    "    'last_pymnt_amnt',\n",
    "    'next_pymnt_d',\n",
    "    'last_credit_pull_d',\n",
    "    'collections_12_mths_ex_med',\n",
    "    'mths_since_last_major_derog',\n",
    "    'policy_code',\n",
    "    'tot_coll_amt',\n",
    "    'tot_cur_bal', \n",
    "    'open_acc_6m',\n",
    "    'open_il_6m', \n",
    "    'open_il_12m', \n",
    "    'open_il_24m', \n",
    "    'mths_since_rcnt_il', \n",
    "    'total_bal_il', \n",
    "    'il_util', \n",
    "    'open_rv_12m' ,\n",
    "    'open_rv_24m', \n",
    "    'max_bal_bc', \n",
    "    'all_util', \n",
    "    'inq_fi', \n",
    "    'total_cu_tl', \n",
    "    'inq_last_12m',\n",
    "    'grade'\n",
    "]\n",
    "\n",
    "df = df.drop(remove_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize default_ind attribute\n",
    "\n",
    "sns.countplot(data=df, x='default_ind')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New feature using user defined transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditUtilizationRatioTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, include=True):\n",
    "        self.revol_bal_col = 'revol_bal'\n",
    "        self.annual_inc_col = 'annual_inc'\n",
    "        self.installment_col = 'installment'\n",
    "        self.total_rec_prncp_col = 'total_rec_prncp'\n",
    "        self.funded_amnt_col = 'funded_amnt'\n",
    "\n",
    "        self.include_rev_to_inc_ratio = include\n",
    "        self.include_loan_to_inc_ratio = include\n",
    "        self.include_repayment_progress = include\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Find index of columns\n",
    "        revol_bal_ix = np.where(X.columns == self.revol_bal_col)[0][0]\n",
    "        annual_inc_ix = np.where(X.columns == self.annual_inc_col)[0][0]\n",
    "        installment_ix = np.where(X.columns == self.installment_col)[0][0]\n",
    "        total_rec_prncp_ix = np.where(X.columns == self.total_rec_prncp_col)[0][0]\n",
    "        funded_amnt_ix = np.where(X.columns == self.funded_amnt_col)[0][0]\n",
    "\n",
    "        # Calculate the Revolving Credit Balance to Annual Income Ratio.\n",
    "        rev_to_inc_ratio = X.iloc[:, revol_bal_ix] / X.iloc[:, annual_inc_ix]\n",
    "\n",
    "        # Calculate the Loan Payment-to-Income Ratio.\n",
    "        loan_to_inc_ratio = X.iloc[:, installment_ix] / (X.iloc[:, annual_inc_ix] / 12)\n",
    "\n",
    "        # Calculate the Repayment Progress.\n",
    "        repayment_progress = (X.iloc[:, total_rec_prncp_ix] / X.iloc[:, funded_amnt_ix]) * 100\n",
    "\n",
    "        # Create a copy of the original DataFrame to avoid modifying it directly\n",
    "        X_transformed = X.copy()\n",
    "\n",
    "        # Add the new columns to the DataFrame using .loc\n",
    "        if self.include_rev_to_inc_ratio:\n",
    "            X_transformed.loc[:, 'Rev_to_Inc_Ratio'] = rev_to_inc_ratio\n",
    "\n",
    "        if self.include_loan_to_inc_ratio:\n",
    "            X_transformed.loc[:, 'Loan_Payment_to_Income_Ratio'] = loan_to_inc_ratio\n",
    "\n",
    "        if self.include_repayment_progress:\n",
    "            X_transformed.loc[:, 'Repayment_Progress'] = repayment_progress\n",
    "\n",
    "        return X_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize - Correlation matrix\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Select the correlation values with 'default_ind'\n",
    "target_corr = corr_matrix['default_ind']\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Fresh round of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a: Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (subset of columns from the original dataset)\n",
    "selected_features = ['recoveries', 'collection_recovery_fee', 'out_prncp', 'out_prncp_inv', 'sub_grade', 'revol_bal', 'annual_inc', 'installment', 'total_rec_prncp', 'funded_amnt']\n",
    "\n",
    "# Create the feature matrix X by selecting the columns from the original dataset\n",
    "X_beforeTransformed= df[selected_features]\n",
    "y = df['default_ind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: StratifiedShuffleSplit Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the StratifiedShuffleSplit object\n",
    "stratified_shuffle_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform the split and obtain the indices for training and testing sets\n",
    "for train_index, test_index in stratified_shuffle_split.split(X_beforeTransformed, y):\n",
    "    KNN_X_train, KNN_X_test = X_beforeTransformed.iloc[train_index], X_beforeTransformed.iloc[test_index]\n",
    "    KNN_y_train, KNN_y_test = y.iloc[train_index], y.iloc[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of Test and Train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN_X_train shape:\", KNN_X_train.shape)\n",
    "print(\"KNN_X_test shape:\", KNN_X_test.shape)\n",
    "print(\"KNN_y_train shape:\", KNN_y_train.shape)\n",
    "print(\"KNN_y_test shape:\", KNN_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result: Significantly imbalanced class distribution\n",
    "\n",
    "#### Solution: Have to apply class balancing techniques (e.g. oversampling/SMOTE, or Class-Weighted approach) just before Model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c: Basic K-Neighbour Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set the weights parameter to 'distance'\n",
    "# 'distance' means weights are assigned based on the inverse of the distance\n",
    "KNN_basic_classifier = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Train the classifier on the training data with class weights\n",
    "KNN_basic_classifier.fit(KNN_X_train, KNN_y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "KNN_basic_y_pred = KNN_basic_classifier.predict(KNN_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Fine tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a: + User-defined Transformer Features to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of CreditUtilizationRatioTransformer with desired features included\n",
    "transformer = CreditUtilizationRatioTransformer(\n",
    "    include= True\n",
    ")\n",
    "# Apply the transformer to add the new features to X\n",
    "X_transformed = transformer.transform(X_beforeTransformed)\n",
    "\n",
    "# Now X contains the original selected features along with additional features from the transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedShuffleSplit Re-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the StratifiedShuffleSplit object\n",
    "stratified_shuffle_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform the split and obtain the indices for training and testing sets\n",
    "for train_index, test_index in stratified_shuffle_split.split(X_transformed, y):\n",
    "    KNN_Balanced_X_train, KNN_Balanced_X_test = X_transformed.iloc[train_index], X_transformed.iloc[test_index]\n",
    "    KNN_Balanced_y_train, KNN_Balanced_y_test = y.iloc[train_index], y.iloc[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of Test and Train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN_Balanced_X_train shape:\", KNN_Balanced_X_train.shape)\n",
    "print(\"KNN_Balanced_X_test shape:\", KNN_Balanced_X_test.shape)\n",
    "print(\"KNN_Balanced_y_train shape:\", KNN_Balanced_y_train.shape)\n",
    "print(\"KNN_Balanced_y_test shape:\", KNN_Balanced_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b: Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the nearest n_neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of n_neighbors to test\n",
    "param_grid = {'n_neighbors': range(1, 21)}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "KNNclassifier = KNeighborsClassifier(weights='distance')\n",
    "\n",
    "# Use GridSearchCV or RandomizedSearchCV for hyperparameter tuning\n",
    "# For GridSearchCV:\n",
    "grid_search = GridSearchCV(KNNclassifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(KNN_Balanced_X_train, KNN_Balanced_y_train)\n",
    "\n",
    "# For RandomizedSearchCV:\n",
    "# randomized_search = RandomizedSearchCV(classifier, param_distributions=param_grid, cv=5, scoring='accuracy', n_jobs=-1, n_iter=10)\n",
    "# randomized_search.fit(KNN_Balanced_X_train, KNN_Balanced_y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding performance\n",
    "print(\"Best n_neighbors:\", grid_search.best_params_['n_neighbors'])\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c: Training KNN Model using SMOTE approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Perform SMOTE only on the training data\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(KNN_Balanced_X_train, KNN_Balanced_y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising Data Shape Before and After SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(pd.Series(KNN_Balanced_y_train).value_counts())\n",
    "\n",
    "# After SMOTE\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier on the training data with SMOTE\n",
    "KNN_classifier_smote = KNeighborsClassifier(n_neighbors=4)\n",
    "KNN_classifier_smote.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the trained model\n",
    "KNN_smote_y_pred = KNN_classifier_smote.predict(KNN_Balanced_X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the test set\n",
    "accuracy_smote = accuracy_score(KNN_Balanced_y_test, KNN_smote_y_pred)\n",
    "roc_auc_smote = roc_auc_score(KNN_Balanced_y_test, KNN_smote_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d: Training KNN Model using Class-Weighted approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training  Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set the weights parameter to 'distance'\n",
    "# 'distance' means weights are assigned based on the inverse of the distance\n",
    "class_classifier = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "\n",
    "# Train the classifier on the training data with class weights\n",
    "class_classifier.fit(KNN_Balanced_X_train, KNN_Balanced_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "KNN_class_y_pred = class_classifier.predict(KNN_Balanced_X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "class_accuracy = accuracy_score(KNN_Balanced_y_test, KNN_class_y_pred)\n",
    "roc_auc = roc_auc_score(KNN_Balanced_y_test, KNN_class_y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Evaluate the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, model_name):\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Display the confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-default', 'Default'], yticklabels=['Non-default', 'Default'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=['Non-default', 'Default'], output_dict=True)\n",
    "\n",
    "    # Create a summary table\n",
    "    summary_table = pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'ROC-AUC Score': [roc_auc],\n",
    "        'Precision (Non-default)': [report['Non-default']['precision']],\n",
    "        'Recall (Non-default)': [report['Non-default']['recall']],\n",
    "        'F1-score (Non-default)': [report['Non-default']['f1-score']],\n",
    "        'Precision (Default)': [report['Default']['precision']],\n",
    "        'Recall (Default)': [report['Default']['recall']],\n",
    "        'F1-score (Default)': [report['Default']['f1-score']],\n",
    "    })\n",
    "\n",
    "    return summary_table\n",
    "\n",
    "# Usage:\n",
    "basic_summary = evaluate_predictions(KNN_Balanced_y_test, KNN_basic_y_pred, \"Basic Model\")\n",
    "smote_summary = evaluate_predictions(KNN_Balanced_y_test, KNN_smote_y_pred, \"Balanced Model\")\n",
    "class_summary = evaluate_predictions(KNN_Balanced_y_test, KNN_class_y_pred, \"Class Model\")\n",
    "\n",
    "# Combine all summaries into one DataFrame\n",
    "all_summaries = pd.concat([basic_summary, smote_summary, class_summary], ignore_index=True)\n",
    "\n",
    "# Display the summary table\n",
    "print(all_summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b: Conclusion: Since Class-Weighted approach have better scores across almost all metrics, therefore it is best to use this approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fresh Round of Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (subset of columns from the original dataset)\n",
    "DT_selected_features = [\n",
    "    'collection_recovery_fee'   ,                  \n",
    "    'acc_now_delinq' ,                                    \n",
    "    'funded_amnt'   ,               \n",
    "    'funded_amnt_inv'   ,            \n",
    "    'mths_since_last_record' ,       \n",
    "    'delinq_2yrs'   ,                          \n",
    "    'dti'            ,              \n",
    "    'mths_since_last_delinq'  ,       \n",
    "    'emp_length',                      \n",
    "    'pub_rec'   ,                  \n",
    "    'revol_bal'    ,                                \n",
    "    'credit_history_length'  ,        \n",
    "    'term'   ,                       \n",
    "    'home_ownership' ,                                \n",
    "    'total_rev_hi_lim'  ,              \n",
    "    'total_pymnt'      ,                     \n",
    "    'total_pymnt_inv'  ,              \n",
    "    'purpose'   ,                   \n",
    "    'revol_util'   ,                 \n",
    "    'total_rec_int'   ,               \n",
    "    'inq_last_6mths'  ,              \n",
    "    'total_rec_prncp' ,                        \n",
    "    'sub_grade'        ,             \n",
    "    'total_rec_late_fee'   ,          \n",
    "    'int_rate'   ,                    \n",
    "    'out_prncp_inv'  ,                 \n",
    "    'out_prncp'   ,                       \n",
    "    'recoveries'      ,\n",
    "    'annual_inc'    ,\n",
    "    'installment'\n",
    "\n",
    "]\n",
    "\n",
    "# Create the feature matrix X by selecting the columns from the original dataset\n",
    "DT_X_before_transforming = df[DT_selected_features]\n",
    "DT_y = df['default_ind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b: StratifiedShuffleSplit Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the StratifiedShuffleSplit object\n",
    "DT_stratified_shuffle_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform the split and obtain the indices for training and testing sets\n",
    "for DT_train_index, DT_test_index in DT_stratified_shuffle_split.split(DT_X_before_transforming, DT_y):\n",
    "    DT_X_train, DT_X_test = DT_X_before_transforming.iloc[DT_train_index], DT_X_before_transforming.iloc[DT_test_index]\n",
    "    DT_y_train, DT_y_test = DT_y.iloc[DT_train_index], DT_y.iloc[DT_test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation of Test and Train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"DT_X_train shape:\", DT_X_train.shape)\n",
    "print(\"DT_X_test shape:\", DT_X_test.shape)\n",
    "print(\"DT_y_train shape:\", DT_y_train.shape)\n",
    "print(\"DT_y_test shape:\", DT_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class distribution is significantly imbalance. \n",
    "Class balancing technique such as SMOTE and class-weighted is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c: Basic Decision Tree Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier with random state = 42\n",
    "DT_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "DT_classifier.fit(DT_X_train, DT_y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "DT_y_pred = DT_classifier.predict(DT_X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "DT_basic_accuracy = accuracy_score(DT_y_test, DT_y_pred)\n",
    "print(\"Accuracy:\", DT_basic_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fine tune DT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a: Add User-Defined Transformer Features to X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of CreditUtilizationRatioTransformer with desired features included\n",
    "DT_transformer = CreditUtilizationRatioTransformer(include = True)\n",
    "\n",
    "# Apply the transformer to add the new features to X\n",
    "DT_X_after_transforming = DT_transformer.transform(DT_X_before_transforming)\n",
    "\n",
    "# Now X contains the original selected features along with additional features from the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b: StratifiedShuffleSplit Re-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the StratifiedShuffleSplit object\n",
    "DT_stratified_shuffle_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform the split and obtain the indices for training and testing sets\n",
    "for DT_train_index, DT_test_index in DT_stratified_shuffle_split.split(DT_X_after_transforming, DT_y):\n",
    "    DT_Balanced_X_train, DT_Balanced_X_test = DT_X_after_transforming.iloc[DT_train_index], DT_X_after_transforming.iloc[DT_test_index]\n",
    "    DT_Balanced_y_train, DT_Balanced_y_test = DT_y.iloc[DT_train_index], DT_y.iloc[DT_test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation of Test and Train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"DT_Balanced_X_train shape:\", DT_Balanced_X_train.shape)\n",
    "print(\"DT_Balanced_X_test shape:\", DT_Balanced_X_test.shape)\n",
    "print(\"DT_Balanced_y_train shape:\", DT_Balanced_y_train.shape)\n",
    "print(\"DT_Balanced_y_test shape:\", DT_Balanced_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c: Training Decision Tree Model with hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier with class-weighted training\n",
    "DT_classifier = DecisionTreeClassifier(criterion='entropy',splitter = 'best', max_depth = 10, min_samples_split = 10, min_samples_leaf = 4, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "DT_classifier.fit(DT_Balanced_X_train, DT_Balanced_y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "DT_y_pred = DT_classifier.predict(DT_Balanced_X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "DT_hyperparameter_accuracy = accuracy_score(DT_Balanced_y_test, DT_y_pred)\n",
    "print(\"Accuracy training with hyperparameters:\", DT_hyperparameter_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2d: Training Decision Tree Model using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Perform SMOTE only on the training data\n",
    "DT_Balanced_X_train_SMOTE, DT_Balanced_y_train_SMOTE = smote.fit_resample(DT_Balanced_X_train, DT_Balanced_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising Data Shape Before and After SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(pd.Series(DT_Balanced_y_train).value_counts())\n",
    "\n",
    "# After SMOTE\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(DT_Balanced_y_train_SMOTE).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier on the training data with SMOTE\n",
    "classifier_smote = DecisionTreeClassifier(criterion='entropy',splitter = 'best', max_depth = 10, min_samples_split = 10, min_samples_leaf = 4, class_weight='balanced', random_state=42)\n",
    "classifier_smote.fit(DT_Balanced_X_train_SMOTE, DT_Balanced_y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the trained model\n",
    "DT_y_pred_smote = classifier_smote.predict(DT_Balanced_X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "DT_smote_accuracy = accuracy_score(DT_Balanced_y_test, DT_y_pred_smote)\n",
    "print(\"Accuracy:\", DT_smote_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2e: Training Decision Tree Model using Class-Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier on the training data with class-weighted\n",
    "DT_classifier_class_weighted = DecisionTreeClassifier(criterion='entropy',splitter = 'best', max_depth = 10, min_samples_split = 10, min_samples_leaf = 4, class_weight='balanced', random_state=42)\n",
    "DT_classifier_class_weighted.fit(DT_Balanced_X_train, DT_Balanced_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "DT_y_pred_class = DT_classifier_class_weighted.predict(DT_Balanced_X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "DT_class_accuracy = accuracy_score(DT_Balanced_y_test, DT_y_pred_class)\n",
    "print(\"Accuracy using class weighted:\", DT_class_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2f: Training Decision Tree Model with post-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply post-pruning by varying ccp_alpha\n",
    "ccp_alphas = np.arange(0.0, 0.01, 0.001)\n",
    "DT_best_accuracy = 0.0\n",
    "DT_best_f1_score = 0.0\n",
    "DT_best_alpha = 0.0\n",
    "\n",
    "for alpha in ccp_alphas:\n",
    "    dt_pruned = DecisionTreeClassifier(criterion='entropy',splitter = 'best', max_depth = 10, min_samples_split = 10, min_samples_leaf = 4, class_weight='balanced', random_state=42)\n",
    "    dt_pruned.fit(DT_Balanced_X_train, DT_Balanced_y_train)\n",
    "    DT_y_pred = dt_pruned.predict(DT_Balanced_X_test)\n",
    "    DT_accuracy = accuracy_score(DT_Balanced_y_test, DT_y_pred)\n",
    "    DT_f1_score_weighted = f1_score(DT_Balanced_y_test, DT_y_pred, average='weighted')\n",
    "    \n",
    "    if DT_f1_score_weighted > DT_best_f1_score:\n",
    "        DT_best_f1_score = DT_f1_score_weighted\n",
    "        DT_best_accuracy = DT_accuracy\n",
    "        DT_best_alpha = alpha\n",
    "\n",
    "print(\"Best CCP Alpha:\", DT_best_alpha)\n",
    "print(\"Best Accuracy:\", DT_best_accuracy)\n",
    "print(\"Best Weighted F1 Score:\", DT_best_f1_score)\n",
    "\n",
    "\n",
    "# The best_dt_pruned contains the Decision Tree classifier with the best ccp_alpha\n",
    "DT_best_dt_pruned = DecisionTreeClassifier(criterion='entropy',splitter = 'best', max_depth = 10, min_samples_split = 10, min_samples_leaf = 4, class_weight='balanced', random_state=42)\n",
    "DT_best_dt_pruned.fit(DT_Balanced_X_train, DT_Balanced_y_train)\n",
    "\n",
    "# Make predictions on the test set using the pruned tree\n",
    "DT_y_pred_pruned = DT_best_dt_pruned.predict(DT_Balanced_X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "DT_post_pruning_accuracy = accuracy_score(DT_Balanced_y_test, DT_y_pred_pruned)\n",
    "print(\"Accuracy:\", DT_post_pruning_accuracy)\n",
    "\n",
    "# Perform evaluation or other tasks with the pruned model as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, model_name):\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Display the confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-default', 'Default'], yticklabels=['Non-default', 'Default'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=['Non-default', 'Default'], output_dict=True)\n",
    "\n",
    "    # Create a summary table\n",
    "    summary_table = pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'ROC-AUC Score': [roc_auc],\n",
    "        'Precision (Non-default)': [report['Non-default']['precision']],\n",
    "        'Recall (Non-default)': [report['Non-default']['recall']],\n",
    "        'F1-score (Non-default)': [report['Non-default']['f1-score']],\n",
    "        'Precision (Default)': [report['Default']['precision']],\n",
    "        'Recall (Default)': [report['Default']['recall']],\n",
    "        'F1-score (Default)': [report['Default']['f1-score']],\n",
    "    })\n",
    "\n",
    "    return summary_table\n",
    "\n",
    "# Usage:\n",
    "DT_basic_summary = evaluate_predictions(DT_Balanced_y_test, DT_y_pred, \"Basic Model\")\n",
    "DT_smote_summary = evaluate_predictions(DT_Balanced_y_test, DT_y_pred_smote, \"Smote Model\")\n",
    "DT_pruned_summary = evaluate_predictions(DT_Balanced_y_test, DT_y_pred_pruned, \"Prune Model\")\n",
    "\n",
    "# Combine all summaries into one DataFrame\n",
    "DT_all_summaries = pd.concat([DT_basic_summary, DT_smote_summary, DT_pruned_summary], ignore_index=True)\n",
    "\n",
    "# Display the summary table\n",
    "print(DT_all_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: Since Decision Tree using SMOTE have the best scores across almost all metrics, therefore it is best to use this approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
