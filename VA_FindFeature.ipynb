{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the null value in each attributes\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rev_hi_lim \n",
    "\n",
    "# Fill missing values in total_rev_hi_lim with Simple Imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "total_rev_hi_lim = df['total_rev_hi_lim'].values.reshape(-1,1)\n",
    "total_rev_hi_lim_imputed = imputer.fit_transform(total_rev_hi_lim)\n",
    "df['total_rev_hi_lim'] = total_rev_hi_lim_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home_ownership \n",
    "\n",
    "# Remove rows with value ANY\n",
    "\n",
    "df = df[df['home_ownership'] != 'ANY']\n",
    "df['home_ownership'].unique()\n",
    "\n",
    "# Level encoding for home ownership \n",
    "\n",
    "home_type = ['RENT', 'OWN', 'MORTGAGE', 'OTHER', 'NONE']  # Unique values for encoding\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(home_type)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['home_ownership'] = encoder.transform(df['home_ownership'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose \n",
    "\n",
    "# Label encoding for purpose\n",
    "\n",
    "df['purpose'].unique()\n",
    "\n",
    "purposes = ['credit_card', 'car', 'small_business', 'other', 'wedding',\n",
    "       'debt_consolidation', 'home_improvement', 'major_purchase',\n",
    "       'medical', 'moving', 'vacation', 'house', 'renewable_energy',\n",
    "       'educational']\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(purposes)\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['purpose'] = encoder.transform(df['purpose'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_grade\n",
    "\n",
    "# Sort the order of subgrades and do label encoding\n",
    "\n",
    "subgrades = ['B2', 'C4', 'C5', 'C1', 'B5', 'A4', 'E1', 'F2', 'C3', 'B1', 'D1',\n",
    "       'A1', 'B3', 'B4', 'C2', 'D2', 'A3', 'A5', 'D5', 'A2', 'E4', 'D3',\n",
    "       'D4', 'F3', 'E3', 'F4', 'F1', 'E5', 'G4', 'E2', 'G3', 'G2', 'G1',\n",
    "       'F5', 'G5']\n",
    "\n",
    "def custom_sort_key(subgrade):\n",
    "    match = re.match(r'([A-Za-z]+)(\\d+)', subgrade)\n",
    "    letter = match.group(1)\n",
    "    number = int(match.group(2))\n",
    "    \n",
    "    return letter, number\n",
    "\n",
    "sorted_subgrades = sorted(subgrades, key=custom_sort_key)\n",
    "\n",
    "# Level encoding for sorted sub-grade \n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(sorted_subgrades)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['sub_grade'] = encoder.transform(df['sub_grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employment_lengths\n",
    "\n",
    "employment_lengths = ['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years', 'nan']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder with unique values\n",
    "label_encoder.fit(employment_lengths)\n",
    "\n",
    "# Encode the attribute values\n",
    "df['emp_length'] = label_encoder.transform(df['emp_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_delinq\n",
    "\n",
    "df['mths_since_last_delinq'] = df['mths_since_last_delinq'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_record\n",
    "\n",
    "df['mths_since_last_record'] = df['mths_since_last_record'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revol_util\n",
    "# Handle missing value with imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "revol_util = df['revol_util'].values.reshape(-1,1)\n",
    "\n",
    "revol_util_imputed = imputer.fit_transform(revol_util)\n",
    "\n",
    "df['revol_util'] = revol_util_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate annual_inc and annual_inc_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'annual_inc'] = df.loc[df['application_type'] == 'JOINT', 'annual_inc_joint']\n",
    "df = df.drop('annual_inc_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dti_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'dti'] = df.loc[df['application_type'] == 'JOINT', 'dti_joint']\n",
    "df = df.drop('dti_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification_status_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'verification_status'] = df.loc[df['application_type'] == 'JOINT', 'verification_status_joint']\n",
    "df = df.drop('verification_status_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term \n",
    "# Label encoding for term\n",
    "\n",
    "term = [' 36 months', ' 60 months']  # Unique values for encoding\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(term)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['term'] = encoder.transform(df['term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification_status\n",
    "\n",
    "veri = ['Not Verified', 'Source Verified', 'Verified']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(veri)\n",
    "\n",
    "\n",
    "df['verification_status'] = encoder.transform(df['verification_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymnt_plan\n",
    "\n",
    "plan = ['n', 'y']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(plan)\n",
    "df['pymnt_plan'] = encoder.transform(df['pymnt_plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application_type\n",
    "\n",
    "type = ['INDIVIDUAL', 'JOINT'] # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(type)\n",
    "\n",
    "df['application_type'] = encoder.transform(df['application_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initial_list_status\n",
    "\n",
    "status = ['f', 'w'] # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(status)\n",
    "\n",
    "df['initial_list_status'] = encoder.transform(df['initial_list_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop not usable attributes \n",
    "\n",
    "remove_col = [\n",
    "    'id',\n",
    "    'member_id',\n",
    "    'emp_title',\n",
    "    'issue_d',\n",
    "    'desc',\n",
    "    'title',\n",
    "    'zip_code',\n",
    "    'addr_state',\n",
    "    'earliest_cr_line',\n",
    "    'last_pymnt_d',\n",
    "    'last_pymnt_amnt',\n",
    "    'next_pymnt_d',\n",
    "    'last_credit_pull_d',\n",
    "    'collections_12_mths_ex_med',\n",
    "    'mths_since_last_major_derog',\n",
    "    'policy_code',\n",
    "    'tot_coll_amt',\n",
    "    'tot_cur_bal', \n",
    "    'open_acc_6m',\n",
    "    'open_il_6m', \n",
    "    'open_il_12m', \n",
    "    'open_il_24m', \n",
    "    'mths_since_rcnt_il', \n",
    "    'total_bal_il', \n",
    "    'il_util', \n",
    "    'open_rv_12m' ,\n",
    "    'open_rv_24m', \n",
    "    'max_bal_bc', \n",
    "    'all_util', \n",
    "    'inq_fi', \n",
    "    'total_cu_tl', \n",
    "    'inq_last_12m',\n",
    "    'grade'\n",
    "]\n",
    "\n",
    "df = df.drop(remove_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize default_ind attribute\n",
    "\n",
    "sns.countplot(data=df, x='default_ind')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New feature using user defined transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Constructor\n",
    "class CreditUtilizationRatioTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, include_credit_utilization=True):\n",
    "        self.revol_bal_col = 'revol_bal'\n",
    "        self.total_rev_hi_lim_col = 'total_rev_hi_lim'\n",
    "        self.include_credit_utilization = include_credit_utilization\n",
    "\n",
    "    # Fit not required -> return self\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Find index of columns\n",
    "        revol_bal_ix = np.where(X.columns == self.revol_bal_col)[0][0]\n",
    "        total_rev_hi_lim_ix = np.where(X.columns == self.total_rev_hi_lim_col)[0][0]\n",
    "\n",
    "        # Calculate the Credit Utilization Ratio.\n",
    "        credit_utilization_ratio = X.iloc[:, revol_bal_ix] / X.iloc[:, total_rev_hi_lim_ix]\n",
    "\n",
    "        if self.include_credit_utilization:\n",
    "            # Add the calculated Credit Utilization Ratio as a new column to the input data.\n",
    "            X['Credit_Utilization_Ratio'] = credit_utilization_ratio\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the column names for 'revol_bal' and 'total_rev_hi_lim'.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Create an instance of the transformer without including the 'Credit Utilization Ratio' feature:\n",
    "transformer_no_credit = CreditUtilizationRatioTransformer(revol_bal_col=revol_bal_col_name,\n",
    "                                                          total_rev_hi_lim_col=total_rev_hi_lim_col_name,\n",
    "                                                          include_credit_utilization=False)\n",
    "\n",
    "# Apply the transformer without the 'Credit Utilization Ratio' feature:\n",
    "transformed_data_no_credit = transformer_no_credit.transform(df)\n",
    "\n",
    "'''\n",
    "\n",
    "# Now, create an instance of the transformer with the 'Credit Utilization Ratio' feature:\n",
    "transformer_with_credit = CreditUtilizationRatioTransformer(include_credit_utilization=True)\n",
    "\n",
    "# Apply the transformer with the 'Credit Utilization Ratio' feature, and the feature will be added directly to df:\n",
    "transformed_data_with_credit = transformer_with_credit.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize - Correlation matrix\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Select the correlation values with 'default_ind'\n",
    "target_corr = corr_matrix['default_ind']\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone create your own branch, note book and copy the pre processing part, train your own model. Combine together in this file at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eveluate the outcome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
