{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover and visualise the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_col = [\n",
    "    'id',\n",
    "    'member_id',\n",
    "    'emp_title',\n",
    "    'issue_d',\n",
    "    'desc',\n",
    "    'title',\n",
    "    'zip_code',\n",
    "    'addr_state',\n",
    "    'earliest_cr_line',\n",
    "    'last_pymnt_d',\n",
    "    'last_pymnt_amnt',\n",
    "    'next_pymnt_d',\n",
    "    'last_credit_pull_d',\n",
    "    'collections_12_mths_ex_med',\n",
    "    'mths_since_last_major_derog',\n",
    "    'policy_code',\n",
    "\n",
    "    # Vu Anh\n",
    "    # 'home-ownership'\n",
    "    # 'purpose', \n",
    "    # 'sub_grade',\n",
    "    # 'tot_coll_amt', \n",
    "    # 'tot_cur_bal', \n",
    "    # 'open_acc_6m', \n",
    "    # 'open_il_6m', \n",
    "\n",
    "    # Darrel\n",
    "    'open_il_12m', \n",
    "    'open_il_24m', \n",
    "    'mths_since_rcnt_il', \n",
    "    'total_bal_il', \n",
    "    'il_util', \n",
    "    'open_rv_12m' ,\n",
    "    'open_rv_24m', \n",
    "\n",
    "    # Vanness\n",
    "    'max_bal_bc', \n",
    "    'all_util', \n",
    "    'total_rev_hi_lim', \n",
    "    'inq_fi', \n",
    "    'total_cu_tl', \n",
    "    'inq_last_12m'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle home-ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with value ANY\n",
    "\n",
    "df = df[df['home_ownership'] != 'ANY']\n",
    "\n",
    "df['home_ownership'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level encoding for home ownership \n",
    "\n",
    "home_type = ['RENT', 'OWN', 'MORTGAGE', 'OTHER', 'NONE']  # Unique values for encoding\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(home_type)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['home_ownership'] = encoder.transform(df['home_ownership'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['purpose'].unique()\n",
    "\n",
    "purposes = ['credit_card', 'car', 'small_business', 'other', 'wedding',\n",
    "       'debt_consolidation', 'home_improvement', 'major_purchase',\n",
    "       'medical', 'moving', 'vacation', 'house', 'renewable_energy',\n",
    "       'educational']\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(purposes)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['purpose'] = encoder.transform(df['purpose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each label\n",
    "label_counts = df['purpose'].value_counts().sort_index()\n",
    "\n",
    "# Print the label counts\n",
    "\n",
    "'''\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle sub_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sub-grade is a more detailed classification that further divides borrowers within each grade. It typically includes additional factors such as credit history, employment stability, and debt-to-income ratio. This additional level of detail can help in distinguishing the risk profile of borrowers within the same grade.\n",
    "\n",
    "This is why we should keep the subgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sub_grade'].unique()\n",
    "\n",
    "# TODO: check if we should use data binning for this attribute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make best use of level encoding, we sort the sub-grade by order to present the relationship between subgrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgrades = ['B2', 'C4', 'C5', 'C1', 'B5', 'A4', 'E1', 'F2', 'C3', 'B1', 'D1',\n",
    "       'A1', 'B3', 'B4', 'C2', 'D2', 'A3', 'A5', 'D5', 'A2', 'E4', 'D3',\n",
    "       'D4', 'F3', 'E3', 'F4', 'F1', 'E5', 'G4', 'E2', 'G3', 'G2', 'G1',\n",
    "       'F5', 'G5']\n",
    "\n",
    "def custom_sort_key(subgrade):\n",
    "    match = re.match(r'([A-Za-z]+)(\\d+)', subgrade)\n",
    "    letter = match.group(1)\n",
    "    number = int(match.group(2))\n",
    "    \n",
    "    return letter, number\n",
    "\n",
    "sorted_subgrades = sorted(subgrades, key=custom_sort_key)\n",
    "\n",
    "print(sorted_subgrades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level encoding for sorted sub-grade \n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(sorted_subgrades)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['sub_grade'] = encoder.transform(df['sub_grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sub_grade'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle 'tot_coll_amt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tot_coll_amt'].isna().any()\n",
    "\n",
    "# There are 67313 na values for tot_coll_amt\n",
    "\n",
    "# Handle missing values \n",
    "\n",
    "df['tot_coll_amt'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values using Simple Imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "tot_coll_amt = df['tot_coll_amt'].values.reshape(-1,1)\n",
    "\n",
    "tot_coll_amt_imputed = imputer.fit_transform(tot_coll_amt)\n",
    "\n",
    "df['tot_coll_amt'] = tot_coll_amt_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hanle 'tot_cur_bal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tot_cur_bal'].isna().any()\n",
    "\n",
    "# Need to handle missing values using simple imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "tot_cur_bal = df['tot_cur_bal'].values.reshape(-1,1)\n",
    "\n",
    "tot_cur_bal_imputed = imputer.fit_transform(tot_cur_bal)\n",
    "\n",
    "df['tot_cur_bal'] = tot_cur_bal_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle open_acc_6m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Risk of Overextension: A higher number of newly opened accounts may suggest that the borrower has taken on additional credit obligations in a relatively short period. This could indicate a higher risk of overextension, where the borrower may have difficulty managing multiple credit accounts simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['open_acc_6m'].unique()\n",
    "\n",
    "# Handle missing value using Simple Imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "open_acc_6m = df['open_acc_6m'].values.reshape(-1,1)\n",
    "\n",
    "open_acc_6m_imputed = imputer.fit_transform(open_acc_6m)\n",
    "\n",
    "df['open_acc_6m'] = open_acc_6m_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle 'open_il_6m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent Credit Activity: 'open_il_6m' provides insights into the borrower's recent credit behavior and the number of installment accounts they have opened within the last 6 months. A higher number of open installment accounts may indicate an increased demand for credit or a need for additional funds, which could impact the borrower's creditworthiness assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['open_il_6m'].unique()\n",
    "\n",
    "# TODO: check if we should use data binning for this attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values using simple imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "open_il_6m = df['open_il_6m'].values.reshape(-1,1)\n",
    "\n",
    "open_il_6m_imputed = imputer.fit_transform(open_il_6m)\n",
    "\n",
    "df['open_il_6m'] = open_il_6m_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(remove_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all attributes with missing values\n",
    "\n",
    "null_columns = df.columns[df.isnull().any()] \n",
    "null_columns_result = df.isnull().any()[null_columns] \n",
    "null_columns_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emp_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp_length'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder with unique values\n",
    "label_encoder.fit(df['emp_length'].unique())\n",
    "\n",
    "# Encode the attribute values\n",
    "df['emp_length'] = label_encoder.transform(df['emp_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp_length'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mths_since_last_delinq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mths_since_last_delinq'] = df['mths_since_last_delinq'].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mths_since_last_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mths_since_last_record'] = df['mths_since_last_record'].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### revol_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "revol_util = df['revol_util'].values.reshape(-1,1)\n",
    "\n",
    "revol_util_imputed = imputer.fit_transform(revol_util)\n",
    "\n",
    "df['revol_util'] = revol_util_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annual_inc_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate annual_inc and annual_inc_joint\n",
    "df.loc[df['application_type'] == 'JOINT', 'annual_inc'] = df.loc[df['application_type'] == 'JOINT', 'annual_inc_joint']\n",
    "df = df.drop('annual_inc_joint', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dti_joint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['application_type'] == 'JOINT', 'dti'] = df.loc[df['application_type'] == 'JOINT', 'dti_joint']\n",
    "df = df.drop('dti_joint', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verification_status_joint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['application_type'] == 'JOINT', 'verification_status'] = df.loc[df['application_type'] == 'JOINT', 'verification_status_joint']\n",
    "df = df.drop('verification_status_joint', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['term'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = [' 36 months', ' 60 months']  # Unique values for encoding\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(term)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['term'] = encoder.transform(df['term'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = ['A', 'B', 'C', 'D', 'E', 'F', 'G']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(grades)\n",
    "\n",
    "df['grade'] = encoder.transform(df['grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verification_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri = ['Not Verified', 'Source Verified', 'Verified']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(veri)\n",
    "\n",
    "\n",
    "df['verification_status'] = encoder.transform(df['verification_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pymnt_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = ['n', 'y']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(plan)\n",
    "\n",
    "df['pymnt_plan'] = encoder.transform(df['pymnt_plan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### application_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = ['INDIVIDUAL', 'JOINT'] # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(type)\n",
    "\n",
    "df['application_type'] = encoder.transform(df['application_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initial_list_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "status = ['f', 'w'] # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(status)\n",
    "\n",
    "df['initial_list_status'] = encoder.transform(df['initial_list_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the new feature\n",
    "df['open_acc_rate'] = df['open_acc'] / df['total_acc']\n",
    "# Swap the values and column names\n",
    "df['open_acc_rate'], df['default_ind'] = df['default_ind'].copy(), df['open_acc_rate'].copy()\n",
    "df.rename(columns={'open_acc_rate': 'default_ind', 'default_ind': 'open_acc_rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Select the correlation values with 'default_ind'\n",
    "target_corr = corr_matrix['default_ind']\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the absolute values of the correlation\n",
    "abs_corr = target_corr.abs()\n",
    "\n",
    "# Sort the absolute correlation values\n",
    "sorted_corr = abs_corr.sort_values(ascending=False)\n",
    "\n",
    "# Display the attribute ranking\n",
    "attribute_ranking = sorted_corr.reset_index()\n",
    "attribute_ranking.columns = ['Attribute', 'Absolute Correlation']\n",
    "attribute_ranking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
